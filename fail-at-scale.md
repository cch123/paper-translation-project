# Fail at Scale

original: [Fail at Scale](https://queue.acm.org/detail.cfm?id=2839461)

morning paper: [Fail at Scale](https://blog.acolyer.org/2015/11/19/fail-at-scale-controlling-queue-delay/)

# Morning Paper Article Translation

Ben Maurer最近为ACM Queue写了一篇很棒的文章，介绍了Facebook如何在快速变化中实现可靠性。

> 为了在快速变化的情况下保持Facebook的可靠性，我们研究了故障的常见模式，并建立了解决这些问题的抽象概念。这些抽象确保了最佳实践被应用于我们的整个基础设施。为了指导我们建立可靠性抽象的工作，我们必须了解我们的故障。我们通过建立工具来诊断问题，并创造一种审查事件的文化，以推动我们做出改进，防止未来的失败。

毛雷尔描述了 "导致事件发生的三种简单方式"，并针对每一种方式给出了缓解的策略。这三种方式是。

1. 快速部署的配置变化（见Facebook的整体配置管理）。
2. 对核心服务的硬性依赖（不要因为服务是核心，就认为它们永远不会宕机），以及
3. 延迟和资源耗尽的增加

这是一篇伟大的文章，非常值得一读。今天我想强调的是关于缓解资源耗尽的策略部分。其中也有三个：可控延迟（CoDel），自适应后进先出（Adaptive LIFO），以及并发控制。

Facebook的受控延迟
> 在分析过去涉及延迟的事件时，我们发现许多最糟糕的事件涉及到大量的请求坐在队列中等待处理......我们研究了关于缓冲漂移的研究，因为我们的问题似乎很相似--需要在拥堵期间排队获得可靠性而不造成过度延迟。我们试验了CoDel（控制延迟）算法的一个变种。

# Paper Translation

失败是任何大规模系统工程的一部分。Facebook的文化价值之一是拥抱失败。这可以从我们门洛帕克总部墙上悬挂的海报中看出。"如果你不害怕，你会怎么做？"和 "命运眷顾大胆者"。

为了使Facebook在面对快速变化时保持可靠，我们研究了失败的常见模式，并建立了解决这些问题的抽象方法。这些抽象确保了最佳实践在我们整个基础设施中的应用。为了指导我们建立可靠性抽象的工作，我们必须了解我们的故障。我们通过建立工具来诊断问题，并创造一种审查事件的文化，以推动我们做出改进，防止未来的失败。

## 为什么会发生故障？

虽然每个故障都有一个独特的故事，但许多故障可归结为少数基本的根本原因。

**单个机器的故障**

通常情况下，一个单独的机器会遇到一个孤立的故障，不会影响到基础设施的其他部分。例如，也许一台机器的硬盘出现了故障，或者某台机器上的服务遇到了代码中的错误，如内存损坏或死锁。

避免单个机器故障的关键是自动化。通过将已知的故障模式（如有S.M.A.R.T.错误的硬盘）与寻找未知问题的症状（例如，通过换掉响应时间异常慢的服务器）相结合，自动化效果最佳。当自动化发现一个未知问题的症状时，人工调查可以帮助开发更好的工具来检测和修复未来的问题。

**合法的工作负荷变化**
有时，Facebook用户改变了他们的行为，给我们的基础设施带来了挑战。例如，在重大的世界事件中，独特的工作负载类型可能会以不寻常的方式给我们的基础设施带来压力。当巴拉克-奥巴马赢得2008年美国总统选举时，他的Facebook页面经历了创纪录的活动水平。重大体育赛事的高潮部分，如超级碗或世界杯，会导致极高的帖子数量。负载测试，包括 "暗中启动"，即一个功能被激活但对用户不可见，有助于确保新功能能够处理负载。

在这类事件中收集到的统计数据往往为系统的设计提供一个独特的视角。通常情况下，重大事件会导致用户行为的改变（例如，通过围绕一个特定的对象产生集中的活动）。关于这些变化的数据往往指向设计决策，从而使后续事件的运行更加顺畅。

**人为错误**

鉴于Facebook鼓励工程师们 "快速行动，打破常规"--这是装饰办公室的另一张海报，人们可能会认为许多错误是由人类造成的。我们的数据表明，人为错误是导致我们失败的一个因素。图1包括对严重到足以被视为违反SLA（服务级别协议）的事件的时间分析数据。每一个违反事件都表明我们的内部可靠性目标没有得到满足，并导致警报的产生。由于我们的目标是严格的，这些事件中的大多数都是小事，对网站的用户来说并不引人注目。图1a显示了周六和周日发生的事件是如何大幅减少的，尽管网站的流量在整个一周内保持一致。图1b显示了在六个月的时间里，只有两个星期没有发生事件：圣诞节的那一周和员工要为对方写同行评论的那一周。

![](https://dl.acm.org/cms/attachment/620d2cef-e001-466b-a80b-eb4c836eb1b6/maurer1.png)

这两个数据似乎表明，当Facebook的员工因为忙于其他事情（周末、假期，甚至是绩效考核）而没有积极地对基础设施进行修改时，网站的可靠性水平更高。我们相信，这并不是因为进行修改的人粗心大意，而是证明我们的基础设施在面对机器故障等非人为原因的错误时，基本上可以自我修复。

## 造成事故的三种简单方法
虽然故障有不同的根本原因，但我们发现了三种常见的病理现象，它们会放大故障并导致故障的广泛存在。对于每一种病理，我们都制定了预防措施，以减轻大范围的故障。

**快速部署的配置变化**

配置系统往往被设计为在全球范围内快速复制变化。快速配置变化是一个强大的工具，可以让工程师快速管理新产品的推出或调整设置。然而，快速配置变化意味着在部署不良配置时快速失败。我们使用一些做法来防止配置变化导致失败。

- 让每个人都使用一个共同的配置系统。

使用一个共同的配置系统可以确保程序和工具适用于所有类型的配置。在Facebook，我们发现，团队有时会受到诱惑，以一次性的方式处理配置。避免这些诱惑并以统一的方式管理配置，使配置系统成为使网站更可靠的杠杆方式。

- 静态验证配置变化。许多配置系统允许松散类型的配置，如JSON结构。这些类型的配置使工程师很容易打错字段的名称，在需要使用整数的地方使用字符串，或犯其他简单的错误。这类简单的错误最好用静态验证来捕捉。一个结构化的格式（例如，在Facebook我们使用Thrift）4可以提供最基本的验证。然而，编写程序化验证来验证更详细的需求也不是没有道理的。

- 运行一个金丝雀。首先将你的配置部署到你的服务的一个小范围内，可以防止一个变化成为灾难性的。一个金丝雀可以有多种形式。最明显的是A/B测试，例如只对1%的用户启动新的配置。多个A/B测试可以同时进行，你可以使用一段时间的数据来跟踪指标。

然而，就可靠性而言，A/B测试并不能满足我们所有的需求。一个被部署到少数用户的变化，却导致相关服务器崩溃或内存耗尽，显然会产生超出测试中有限用户的影响。A/B测试也很耗费时间。工程师们经常希望在不使用A/B测试的情况下推送小的变化。出于这个原因，Facebook的基础设施自动在一小部分服务器上测试新的配置。例如，如果我们希望向1%的用户部署一个新的A/B测试，我们将首先向1%的用户部署测试，这些用户会冲击少量的服务器。我们对这些服务器进行短时间的监控，以确保它们不会崩溃或出现其他高度可见的问题。这种机制对所有的变化提供了一个基本的 "理智检查"，以确保它们不会引起广泛的故障。

- 坚持好的配置。Facebook的配置系统被设计为在更新配置时，面对失败，保留好的配置。开发人员自然倾向于创建配置系统，当他们收到无效的更新配置时就会崩溃。我们更倾向于在这类情况下保留旧配置的系统，并向系统操作员发出配置更新失败的警报。使用陈旧的配置运行通常比向用户返回错误要好得多。

- 让它容易恢复。有时，尽管尽了最大努力，还是部署了一个坏的配置。迅速找到并恢复变化是解决这类问题的关键。我们的配置系统以版本控制为后盾，使之易于恢复变化。

**对核心服务的硬性依赖**
开发人员倾向于认为，核心服务--如配置管理、服务发现或存储系统--永远不会失败。然而，即使这些核心服务出现短暂的故障，也会变成大规模事件。

- 缓存核心服务的数据。对这些类型的服务的硬性依赖往往是没有必要的。这些服务返回的数据可以被缓存，以便在其中一个系统的短暂故障期间，大多数服务可以继续运行。

- 提供加固的API来使用核心服务。核心服务最好由在使用这些核心服务时遵循最佳实践的通用库来补充。例如，这些库可以提供良好的API来管理缓存或良好的故障处理。

- 进行消防演习。你可能认为你能够在核心服务的中断中存活下来，但在你尝试之前你永远不知道。对于这些类型的中断，我们不得不开发消防演习系统，从应用于单个服务器的故障注入到手动触发的整个数据中心的中断。

**延迟增加和资源耗尽**
一些故障会导致服务对客户的延迟增加。这种延迟的增加可能很小（例如，考虑到一个人为的配置错误，导致CPU使用量增加，但仍在服务的能力范围内），也可能是几乎无限的（一个服务，服务响应的线程已经死锁）。虽然少量的额外延迟可以由Facebook的基础设施轻松处理，但大量的延迟会导致级联故障。几乎所有的服务都有一个未处理请求数量的限制。这个限制可能是由于在一个逐个请求的线程服务中线程数量有限，也可能是由于在一个基于事件的服务中内存有限。如果一个服务遇到大量的额外延迟，那么调用它的服务将耗尽它们的资源。这种故障可以通过许多层的服务传播，造成广泛的故障。

资源耗尽是一种特别具有破坏性的故障模式，因为它允许由一个请求子集使用的服务的故障导致所有请求的故障。例如，想象一下，一个服务调用一个新的实验性服务，该服务只向1%的用户推出。通常情况下，对这个实验性服务的请求需要1毫秒，但由于新服务的失败，请求需要1秒。使用这个新服务的1%的用户的请求可能会消耗很多线程，以至于其他99%的用户的请求都无法运行。

我们已经发现了一些技术，可以避免这种类型的堆积，而且假阳性率低。

- 受控的延迟。在分析过去涉及延迟的事件时，我们发现许多最糟糕的事件涉及大量的请求坐在队列中等待处理。有问题的服务有一个资源限制（如活动线程或内存的数量），并会对请求进行缓冲，以便将使用量保持在限制之下。由于服务无法跟上传入请求的速度，队列会越来越大，直到达到应用定义的极限。为了解决这种情况，我们希望限制队列的大小，而不影响正常运行的可靠性。我们研究了关于缓冲区膨胀的研究，因为我们的问题似乎很相似--需要排队的可靠性，而在拥堵期间不造成过度的延迟。我们试验了CoDel1（受控延迟）算法的一个变体。

onNewRequest(req, queue)。

  如果（queue.lastEmptyTime() < (now - N seconds)）{
     timeout = M ms
  } 否则 {
     超时=N秒。
  }
  queue.enqueue(req, timeout)

在这个算法中，如果队列在过去的N毫秒内没有被清空，那么在队列中花费的时间被限制在M毫秒内。如果服务在过去的N毫秒内已经能够清空队列，那么在队列中花费的时间被限制为N毫秒。这种算法可以防止站队（因为lastEmptyTime将在遥远的过去，导致M-ms的排队超时），同时允许短时间的排队以达到可靠性的目的。虽然让请求有这么短的超时似乎有悖常理，但这个过程允许请求被快速丢弃，而不是在系统无法跟上传入请求的速度时堆积起来。短暂的超时可以确保服务器接受的工作总是比它实际能处理的多一点，所以它永远不会闲置。

这种算法的一个吸引人的特性是，M和N的值往往不需要调整。其他解决站立队列问题的方法，如对队列中的项目数量设置限制或为队列设置超时，需要在每个服务基础上进行调整。我们发现，M值为5毫秒，N值为100毫秒，在广泛的使用情况下，往往能很好地工作。Facebook的开源Wangle库5提供了这种算法的实现，我们的Thrift4框架也使用了这种算法。

- 自适应LIFO（后进先出）。大多数服务以FIFO（先进先出）的顺序处理队列。然而，在大量排队期间，先入的请求往往已经坐了很久，用户可能已经放弃了产生请求的行动。首先处理先进的请求，将资源耗费在一个不太可能使用户受益的请求上，而不是一个刚刚到达的请求。我们的服务使用自适应后进先出法处理请求。在正常的操作条件下，请求是按照先进先出的顺序处理的，但是当一个队列开始形成时，服务器会切换到后进先出的模式。如图2所示，自适应LIFO和CoDel可以很好地配合。CoDel设置了较短的超时时间，防止了长队的建立，而自适应后进先出模式将新的请求放在队列的前面，最大限度地提高了它们满足CoDel设置的最后期限的机会。 HHVM3，Facebook的PHP运行时，包括自适应后进先出算法的实现。

![](https://dl.acm.org/cms/attachment/9f24ddeb-6a31-46a4-8717-388a9f09a116/maurer2.png)

- 并发控制。CoDel和自适应LIFO都在服务器端运行。服务器通常是实施防止延迟措施的最佳场所--服务器往往为大量的客户提供服务，并且通常比其客户拥有更多的信息。然而，有些故障是如此严重，以至于服务器端的控制无法启动。出于这个原因，我们在客户端实施了一个权宜之计。每个客户端都会在每个服务的基础上跟踪未完成的出站请求的数量。当新的请求被发送时，如果对该服务的未决请求的数量超过可配置的数量，该请求将立即被标记为错误。这种机制可以防止单一服务垄断其客户的所有资源。

## 帮助诊断故障的工具
尽管有最好的预防措施，一些故障总是会发生。在停电期间，正确的工具可以迅速找到根本原因，最大限度地减少故障的持续时间。

**使用Cubism的高密度仪表板**
在处理事故时，快速获取信息很重要。好的仪表盘可以让工程师快速评估可能出现异常的指标类型，然后利用这些信息来推测根本原因。然而，我们发现，我们的仪表盘越来越大，以至于难以快速浏览，而且这些仪表盘上显示的图表有太多的线条，无法一目了然，如图3所示。

![](https://dl.acm.org/cms/attachment/2e411c53-b071-4034-bae0-18f2581a821f/maurer3.png)

为了解决这个问题，我们使用Cubism2构建了我们的顶级仪表盘，这是一个用于创建地平线图表的框架--该图表使用颜色对信息进行更密集的编码，允许对多个类似的数据系列进行轻松比较。例如，我们使用Cubism来比较不同数据中心的指标。我们围绕Cubism的工具允许简单的键盘导航，因此工程师可以快速查看多个指标。图4显示了使用面积图和水平线图的不同高度的同一数据集。在面积图版本中，30像素的版本很难阅读。另一方面，地平线图让人非常容易找到峰值，即使是在30像素的高度。

什么刚刚发生了变化？

由于失败的首要原因之一是人为错误，调试失败的最有效方法之一是寻找人类最近的变化。我们在一个叫做OpsStream的工具中收集关于最近的变化的信息，从配置变化到新软件的部署。然而，我们发现随着时间的推移，这个数据源已经变得非常嘈杂。由于数以千计的工程师在进行改变，在一个事件中往往有太多的改变需要评估。

为了解决这个问题，我们的工具试图将故障与相关的变化联系起来。例如，当一个异常被抛出时，除了输出堆栈跟踪外，我们还输出该请求所读取的任何配置设置的值最近发生了变化。通常，产生许多堆栈痕迹的问题的原因就是这些配置值之一。然后，我们可以迅速地对这个问题做出反应--例如，通过恢复配置并让做出改变的工程师参与进来。

![](https://dl.acm.org/cms/attachment/1ffc60b2-b7be-4465-9cf7-457b36d26a6b/maurer4.png)

## 从失败中学习

失败发生后，我们的事件审查过程有助于我们从这些事件中学习。

事件审查过程的目的不是为了指责。没有人因为他或她造成的事件被审查而被解雇。审查的目的是为了了解发生了什么，补救使事件发生的情况，并建立安全机制以减少未来事件的影响。

审查事件的方法
Facebook开发了一种名为DERP（指检测、升级、补救和预防）的方法，以帮助进行富有成效的事件审查。

- 检测。如何检测问题--警报、仪表板、用户报告？

- 升级。正确的人是否迅速介入？这些人是否可以通过警报而不是手动来处理？

- 补救。采取了哪些步骤来解决这个问题？这些步骤是否可以自动化？

- 预防。哪些改进可以消除这种类型的故障再次发生的风险？你如何能优雅地失败，或更快地失败，以减少这次故障的影响？

DERP帮助分析手头事件的每个步骤。在这种分析的帮助下，即使你不能防止这种类型的事件再次发生，你至少能够在下一次更快恢复。

## Move Fast by Breaking Fewer Things

一个 "快速移动 "的心态不一定与可靠性相冲突。为了使这些理念兼容。

Facebook的基础设施提供了安全阀：我们的配置系统可以防止不良配置的快速部署；我们的核心服务为客户提供加固的API以防止故障；我们的核心库可以防止在延迟情况下的资源耗尽。为了处理不可避免的漏网之鱼，我们建立了易于使用的仪表盘和工具，以帮助找到可能导致正在调查的问题的最近变化。最重要的是，在事件发生后，我们利用学到的经验使我们的基础设施更加可靠。

References
1. CoDel (controlled delay) algorithm; http://queue.acm.org/detail.cfm?id=2209336.

2. Cubism; https://square.github.io/cubism/.

3. HipHop Virtual Machine (HHVM); https://github.com/facebook/hhvm/blob/43c20856239cedf842b2560fd768038f52b501db/hphp/util/job-queue.h#L75.

4. Thrift framework; https://github.com/facebook/fbthrift.

5. Wangle library; https://github.com/facebook/wangle/blob/master/wangle/concurrent/Codel.cpp.

Ben Maurer is the tech lead of the Web Foundation team at Facebook, which is responsible for the overall performance and reliability of Facebook's user-facing products. Ben joined Facebook in 2010 as a member of the infrastructure team. Before Facebook, he co-founded reCAPTCHA with Luis von Ahn. Recently, Ben worked with the U.S. Digital Service to improve the use of technology within the federal government.