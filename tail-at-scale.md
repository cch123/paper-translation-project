# The Tail at Scale

original: [The Tail at Scale](https://research.google/pubs/pub40801/)

morning paper: [The Tail at Scale](https://blog.acolyer.org/2015/01/15/the-tail-at-scale/)

# Morning Paper Article Translation

规模化的尾巴 - Dean和Barroso 2013年

我们都已经熟悉了容错的重要性以及实现容错的技术。不太为人所知的是 "尾部容错 "的概念。一个反应不够快的系统对用户来说是笨拙的，并可能对网站/服务的可用性产生严重的负面影响，从而在底线上产生连锁反应。正如Dean和Barroso所转述的，谷歌对响应系统的目标是100ms。

就像容错计算旨在从不太可靠的部分中创造一个可靠的整体一样，大型在线服务需要从不太可预测的部分中创造一个可预测的响应整体；我们把这种系统称为 "延迟尾部容错"，或者简单地称为 "尾部容错"。

有很多原因可以解释为什么现在和将来一个请求可能会比预期的时间长（论文中给了我们八个例子）。为了达到响应目标，我们需要做到多好？如果99%的响应时间都在我们的目标范围内，这够好吗？

考虑一个系统，每个服务器通常在10ms内响应，但99%的百分位数延迟为1秒。如果一个用户请求只在一个这样的服务器上处理，那么100个用户请求中有一个会很慢（一秒钟）。

也许这还算可以。但是请注意，当参与处理一个请求的不仅仅是一台服务器，而是100台时，会发生什么。例如，一个扇形的查询，或大量的微服务对结果的贡献。

如果一个用户请求必须从100个这样的服务器并行收集响应，那么63%的用户请求将需要超过一秒钟。即使是只有一万个请求中的一个在单个服务器层面上遇到超过一秒的延迟的服务，一个有2000个这样的服务器的服务将看到几乎五分之一的用户请求需要超过一秒。

在这种情况下，即使你的99.99%的百分位数的响应时间是可以的，你的20%的用户看到的是一个糟糕的响应时间！！！。对于你自己的情况，很容易计算出来：只要把你可接受的延迟百分位数（例如0.999），提高到参与响应的服务器数量的幂。

对于一个真实的谷歌系统，任何单一请求的延迟为10ms，所有请求完成的99%百分位数是140ms，95%百分位数是70ms。

......这意味着等待最慢的5%的请求完成是造成99%百分位数总时延的一半原因。专注于这些慢速异常值的技术可以使整体服务性能大幅降低。

希望你现在相信，当涉及到响应时间时，尾巴真的可以摇动狗。我们如何设计系统来容忍尾部的延迟，并在整体上保持响应？

首先，你可以通过优先考虑交互式请求，将大的工作单元分解成较小的部分以允许交错进行（也就是减少线头阻塞），并仔细管理后台活动来减少响应时间的变化。有点反直觉的是，将一个后台任务同步到所有机器上同时运行，而不是将其分散在不同的时间里，这样做会更好。花点时间思考一下尾巴的含义就会发现原因......

这种同步在每台机器上同时执行短暂的活动，只减缓那些在短暂的后台活动期间正在处理的互动请求。相反，在没有同步的情况下，一些机器总是在做一些后台活动，把所有请求的延迟尾巴都推了出来。

在一天结束的时候，你永远不可能完全限制延迟的变化，所以你需要考虑能够容忍它的设计模式。这里有7种模式可以提高尾巴的容忍度。

1) 对冲请求：向多个服务器发送相同的请求，并使用首先回来的任何响应。但为了避免计算负载增加一倍或两倍，不要直接发送对冲请求。
推迟发送第二个请求，直到第一个请求的未决时间超过这类请求的预期延迟的第95分位数。这种方法将额外的负载限制在大约5%，同时大大缩短了尾部延迟。

2) 捆绑请求：而不是在发送对冲请求之前进行延迟，在多个服务器上模拟排队请求，但将它们捆绑在一起，但告诉每个服务器还有谁在他们的队列中也有这个请求。当第一个服务器处理该请求时，它告诉其他服务器从他们的队列中取消该请求。由于取消的信息会穿越网络...
......对于客户端来说，在发送第一个请求和发送第二个请求之间引入一个小的延迟，即平均nework消息延迟的2倍（在现代数据中心网络中为1ms或更少）是有用的。

在一个真实的谷歌系统中，这种捆绑式请求机制将中位数延迟降低了16%，在99.9%的百分位数上降低了40%。

3）微分区：拥有比服务器多得多的分区，以帮助解决不平衡问题。
例如，每台机器平均有20个分区，系统可以以大约5%的增量来减轻负载，时间是系统简单地将分区与机器进行一对一映射的1/20。

4）有选择地增加复制因子：为你检测到的或预测到的会很热的分区增加复制因子。然后，负载均衡器可以帮助分散负载。
谷歌的主要网络搜索系统采用了这种方法，在多个微分区中对流行和重要的文件进行额外的复制。

5）将慢速机器置于试用期。当检测到一台慢速机器时，暂时将其排除在操作之外（断路器）。由于缓慢的源头往往是暂时的，监测何时使受影响的系统重新上线。
继续向这些被排除的服务器发出影子请求，收集它们的延迟统计数据，以便在问题缓解时将它们重新纳入服务中。

6）考虑 "足够好 "的响应。一旦所有的服务器中有足够的一部分做出了响应，用户可能会得到最好的服务，即得到轻微的不完整的结果，以换取更好的端到端延迟。也请看相关的调光开关的概念。
7）使用金丝雀请求。

在具有非常高扇出的系统中可能发生的另一个问题是，一个特定的请求行使一个未经测试的代码路径，导致崩溃或同时在成千上万的服务器上出现极长的延迟。为了防止这种相关的崩溃情况，谷歌的一些IR系统采用了一种叫做 "金丝雀请求 "的技术；根服务器并不是一开始就把一个请求发送给成千上万的叶子服务器，而是先把它发送给一个或两个叶子服务器。其余的服务器只有在根服务器在合理的时间内从金丝雀那里得到成功的响应时才会被查询。

# Paper Translation

TODO
