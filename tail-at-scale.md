# The Tail at Scale

original: [The Tail at Scale](https://research.google/pubs/pub40801/)

morning paper: [The Tail at Scale](https://blog.acolyer.org/2015/01/15/the-tail-at-scale/)

# Morning Paper Article Translation

规模化的尾巴 - Dean和Barroso 2013年

我们都已经熟悉了容错的重要性以及实现容错的技术。不太为人所知的是 "尾部容错 "的概念。一个反应不够快的系统对用户来说是笨拙的，并可能对网站/服务的可用性产生严重的负面影响，从而在底线上产生连锁反应。正如Dean和Barroso所转述的，谷歌对响应系统的目标是100ms。

就像容错计算旨在从不太可靠的部分中创造一个可靠的整体一样，大型在线服务需要从不太可预测的部分中创造一个可预测的响应整体；我们把这种系统称为 "延迟尾部容错"，或者简单地称为 "尾部容错"。

有很多原因可以解释为什么现在和将来一个请求可能会比预期的时间长（论文中给了我们八个例子）。为了达到响应目标，我们需要做到多好？如果99%的响应时间都在我们的目标范围内，这够好吗？

考虑一个系统，每个服务器通常在10ms内响应，但99%的百分位数延迟为1秒。如果一个用户请求只在一个这样的服务器上处理，那么100个用户请求中有一个会很慢（一秒钟）。

也许这还算可以。但是请注意，当参与处理一个请求的不仅仅是一台服务器，而是100台时，会发生什么。例如，一个扇形的查询，或大量的微服务对结果的贡献。

如果一个用户请求必须从100个这样的服务器并行收集响应，那么63%的用户请求将需要超过一秒钟。即使是只有一万个请求中的一个在单个服务器层面上遇到超过一秒的延迟的服务，一个有2000个这样的服务器的服务将看到几乎五分之一的用户请求需要超过一秒。

在这种情况下，即使你的99.99%的百分位数的响应时间是可以的，你的20%的用户看到的是一个糟糕的响应时间！！！。对于你自己的情况，很容易计算出来：只要把你可接受的延迟百分位数（例如0.999），提高到参与响应的服务器数量的幂。

对于一个真实的谷歌系统，任何单一请求的延迟为10ms，所有请求完成的99%百分位数是140ms，95%百分位数是70ms。

......这意味着等待最慢的5%的请求完成是造成99%百分位数总时延的一半原因。专注于这些慢速异常值的技术可以使整体服务性能大幅降低。

希望你现在相信，当涉及到响应时间时，尾巴真的可以摇动狗。我们如何设计系统来容忍尾部的延迟，并在整体上保持响应？

首先，你可以通过优先考虑交互式请求，将大的工作单元分解成较小的部分以允许交错进行（也就是减少线头阻塞），并仔细管理后台活动来减少响应时间的变化。有点反直觉的是，将一个后台任务同步到所有机器上同时运行，而不是将其分散在不同的时间里，这样做会更好。花点时间思考一下尾巴的含义就会发现原因......

这种同步在每台机器上同时执行短暂的活动，只减缓那些在短暂的后台活动期间正在处理的互动请求。相反，在没有同步的情况下，一些机器总是在做一些后台活动，把所有请求的延迟尾巴都推了出来。

在一天结束的时候，你永远不可能完全限制延迟的变化，所以你需要考虑能够容忍它的设计模式。这里有7种模式可以提高尾巴的容忍度。

1) 对冲请求：向多个服务器发送相同的请求，并使用首先回来的任何响应。但为了避免计算负载增加一倍或两倍，不要直接发送对冲请求。
推迟发送第二个请求，直到第一个请求的未决时间超过这类请求的预期延迟的第95分位数。这种方法将额外的负载限制在大约5%，同时大大缩短了尾部延迟。

2) 捆绑请求：而不是在发送对冲请求之前进行延迟，在多个服务器上模拟排队请求，但将它们捆绑在一起，但告诉每个服务器还有谁在他们的队列中也有这个请求。当第一个服务器处理该请求时，它告诉其他服务器从他们的队列中取消该请求。由于取消的信息会穿越网络...
......对于客户端来说，在发送第一个请求和发送第二个请求之间引入一个小的延迟，即平均nework消息延迟的2倍（在现代数据中心网络中为1ms或更少）是有用的。

在一个真实的谷歌系统中，这种捆绑式请求机制将中位数延迟降低了16%，在99.9%的百分位数上降低了40%。

3）微分区：拥有比服务器多得多的分区，以帮助解决不平衡问题。
例如，每台机器平均有20个分区，系统可以以大约5%的增量来减轻负载，时间是系统简单地将分区与机器进行一对一映射的1/20。

4）有选择地增加复制因子：为你检测到的或预测到的会很热的分区增加复制因子。然后，负载均衡器可以帮助分散负载。
谷歌的主要网络搜索系统采用了这种方法，在多个微分区中对流行和重要的文件进行额外的复制。

5）将慢速机器置于试用期。当检测到一台慢速机器时，暂时将其排除在操作之外（断路器）。由于缓慢的源头往往是暂时的，监测何时使受影响的系统重新上线。
继续向这些被排除的服务器发出影子请求，收集它们的延迟统计数据，以便在问题缓解时将它们重新纳入服务中。

6）考虑 "足够好 "的响应。一旦所有的服务器中有足够的一部分做出了响应，用户可能会得到最好的服务，即得到轻微的不完整的结果，以换取更好的端到端延迟。也请看相关的调光开关的概念。
7）使用金丝雀请求。

在具有非常高扇出的系统中可能发生的另一个问题是，一个特定的请求行使一个未经测试的代码路径，导致崩溃或同时在成千上万的服务器上出现极长的延迟。为了防止这种相关的崩溃情况，谷歌的一些IR系统采用了一种叫做 "金丝雀请求 "的技术；根服务器并不是一开始就把一个请求发送给成千上万的叶子服务器，而是先把它发送给一个或两个叶子服务器。其余的服务器只有在根服务器在合理的时间内从金丝雀那里得到成功的响应时才会被查询。

# Paper Translation

对用户行为做出快速反应的系统（100毫秒内）比那些需要更长时间的系统让用户感觉更流畅和自然。互联网连接的改进和仓库级计算系统的兴起2使得网络服务能够在咨询跨越数千台服务器的百万字节数据集时提供流畅的响应；例如，谷歌搜索系统在用户输入时交互式地更新查询结果，根据迄今为止输入的前缀预测最可能的查询，在几十毫秒内执行搜索并显示结果。新兴的增强现实设备（如谷歌眼镜原型7）将需要相关的网络服务，其响应速度甚至更高，以保证无缝的互动性。

随着系统规模和复杂性的扩大，或者整体使用量的增加，服务提供商要保持交互式服务的延迟分布尾部较短，这是一个挑战。暂时的高延迟事件（在中等规模的系统中并不重要）可能会在大规模的情况下主导整个服务性能。就像容错计算旨在从不太可靠的部分中创造一个可靠的整体一样，大型在线服务需要从不太可预测的部分中创造一个可预测的响应整体；我们把这种系统称为 "延迟尾部容忍"，或者简单地称为 "尾部容忍"。在这里，我们概述了大型在线服务中高延迟事件的一些常见原因，并描述了降低其严重性或减轻其对整个系统性能影响的技术。在许多情况下，尾部容错技术可以利用已经部署的资源来实现容错，导致低的额外开销。我们探讨了这些技术如何在不延长延迟尾巴的情况下提高系统利用率，从而避免浪费的过度配置。

## Why Variability Exists?

导致服务的单个组件的高尾部延迟的响应时间的可变性可能由于许多原因产生，包括。

共享的资源。机器可能被争夺共享资源（如CPU核心、处理器缓存、内存带宽和网络带宽）的不同应用所共享，而在同一应用中，不同的请求可能争夺资源。

守护程序。后台守护程序可能平均只使用有限的资源，但在安排时可能会产生几毫秒的中断。

全局资源共享。在不同机器上运行的应用程序可能会争夺全球资源（如网络交换机和共享文件系统）。

维护活动。后台活动（如分布式文件系统中的数据重建，BigTable等存储系统中的定期日志压缩，4以及垃圾收集语言中的定期垃圾收集）会导致周期性的延迟高峰；以及

排队。中间服务器和网络交换机中的多层队列放大了这种可变性。

变异性的增加也是由于几个硬件趋势造成的。

功率限制。现代的CPU被设计成可以暂时运行在其平均功率包络之上，如果这种活动持续很长时间，可以通过节流来减轻热效应；5

垃圾收集。固态存储设备提供了非常快的随机读取访问，但是需要定期对大量的数据块进行垃圾收集，即使是适度的写入活动，也会使读取延迟增加100倍；和

能源管理。许多类型的设备的省电模式可以节省相当多的能量，但在从非活动模式转为活动模式时，会增加额外的延迟。

## Component-Level Variability Amplified By Scale

在大规模的在线服务中，减少延迟的常见技术是在许多不同的机器上并行化子操作，其中每个子操作都与大数据集的部分共处一地。并行化是通过将一个请求从根部分散到大量的叶子服务器并通过请求分配树合并响应来实现的。这些子操作必须在一个严格的期限内完成，以使服务感到有反应。

单个组件的延迟分布的可变性在服务层面上被放大；例如，考虑一个系统，每个服务器通常在10ms内响应，但99分位数的延迟为1秒。如果一个用户请求只在一个这样的服务器上处理，那么100个用户请求中有一个会很慢（一秒钟）。这里的图表概述了在这种假设的情况下，服务级别的延迟是如何被非常小的延迟离群值影响的。如果一个用户请求必须从100个这样的服务器并行收集响应，那么63%的用户请求将需要超过一秒钟（图中标记为 "x"）。即使对于只有一万个请求中的一个在单台服务器上遇到超过一秒的延迟的服务，有2000个这样的服务器的服务将看到几乎五分之一的用户请求需要超过一秒（图中标记为 "o"）。

表1列出了一个真实的谷歌服务的测量结果，该服务在逻辑上与这个理想化的场景相似；根服务器通过中间服务器将一个请求分发到非常多的叶服务器。该表显示了大扇形分布对延迟分布的影响。在根服务器上测量的单个随机请求完成的第99百分位延迟是10ms。然而，所有请求完成的第99百分位数延迟是140ms，95%的请求完成的第99百分位数延迟是70ms，这意味着等待最慢的5%的请求完成要对总的99百分位数延迟的一半负责。专注于这些慢的异常值的技术可以在整体服务性能上产生巨大的减少。

超额配置资源、仔细的软件实时工程和改进的可靠性都可以在所有级别和所有组件中使用，以减少变化的基本原因。接下来，我们将描述对减少服务响应能力的变异性有用的一般方法。

## Reducing Component Variability

通过许多小的工程决策，确保交互式请求得到及时的服务，可以减少交互式响应时间的变异性，包括：。

差异化的服务类别和更高层次的排队。差异化的服务类别可以用来优先调度用户正在等待的请求，而不是非交互式请求。保持低级队列较短，以便更高级别的策略更快生效；例如，谷歌集群级文件系统软件中的存储服务器在操作系统的磁盘队列中很少保持未完成的操作，而是维护自己的待处理磁盘请求的优先级队列。这种浅层队列允许服务器在延迟不敏感的批量操作的旧请求被送达之前发出传入的高优先级互动请求。

减少线头阻塞。高级别的服务可以处理具有广泛不同的内在成本的请求。有时，系统将长期运行的请求分成一连串较小的请求，以允许交错执行其他短期运行的请求，这是非常有用的；例如，谷歌的网络搜索系统使用这种时间分割，以防止少数计算成本非常高的查询为大量并发的廉价查询增加大量的延迟。

管理后台活动和同步中断。后台任务可以产生巨大的CPU、磁盘或网络负载；例子是面向日志的存储系统的日志压缩和垃圾收集语言的垃圾收集器活动。结合节流、将重量级操作分解成较小的操作，并在整体负载较低的时候触发这些操作，通常能够减少后台活动对交互式请求延迟的影响。对于大型的扇出服务，系统在许多不同的机器上同步后台活动有时是有用的。这种同步在每台机器上同时执行短暂的活动，只减缓那些在短暂的背景活动期间处理的交互式请求。相反，如果没有同步，一些机器总是在进行一些后台活动，从而使所有请求的延迟尾部被推开。

到目前为止，在这个讨论中还没有提到缓存。虽然有效的缓存层是有用的，甚至在某些系统中是必须的，但它们并不能直接解决尾部延迟问题，除了那些保证应用程序的整个工作集都在缓存中的配置。

## Living with Latency Variability

前面一节中仔细的工程技术对于构建高性能的交互式服务是至关重要的，但是现代Web服务的规模和复杂性使得消除所有的延迟变化是不可行的。即使这种完美的行为可以在孤立的环境中实现，具有共享计算资源的系统也会表现出应用开发者无法控制的性能波动。因此，谷歌发现开发容尾技术是有利的，它可以掩盖或解决暂时的延迟病症，而不是试图完全消除它们。我们把这些技术分成两个主要类别。第一类对应的是请求内的即时响应技术，这些技术在几十毫秒的时间范围内运行，在长期技术有机会做出反应之前。第二类是跨请求的长期适应，在几十秒到几分钟的时间范围内执行，旨在掩盖长期现象的影响。

## Within Request Short-Term Adaptations

一大类Web服务部署了数据项的多个副本，以提供额外的吞吐能力，并在出现故障时保持可用性。当大多数请求在很大程度上是只读的、松散一致的数据集上操作时，这种方法特别有效；一个例子是拼写纠正服务，它的模型每天更新一次，同时每秒处理成千上万的纠正请求。同样，分布式文件系统可能有一个给定数据块的多个副本，这些副本都可以用来服务于阅读请求。这里的技术显示了复制如何被用来减少单个更高级别的请求中的延迟变化。

**对冲请求**。抑制延迟变化的一个简单方法是向多个副本发出相同的请求，并使用哪个副本首先响应的结果。我们称这种请求为 "对冲请求"，因为客户首先向被认为是最合适的副本发送一个请求，但在短暂的延迟后，又返回到发送第二个请求。一旦收到第一个结果，客户端就会取消剩余的未处理请求。尽管这种技术的天真实现通常会增加不可接受的额外负载，但存在许多变体，它们能提供大部分的延迟减少效果，而只适度地增加负载。

其中一个方法是推迟发送第二个请求，直到第一个请求的未完成时间超过该类请求的预期延迟的第95分位数。这种方法将额外的负载限制在5%左右，同时大大缩短了延迟的尾巴。这种技术之所以有效，是因为延迟的来源往往不是特定请求的内在因素，而是由于其他形式的干扰。例如，在谷歌的一个基准测试中，读取存储在分布在100个不同服务器的BigTable表中的1000个键的值，在延迟10ms后发送对冲请求，将检索所有1000个值的99.9分位数的延迟从1800ms减少到74ms，同时只多发送2%的请求。对冲请求的开销可以通过将其标记为比主请求更低的优先级来进一步减少。

**捆绑式请求**。对冲请求技术也有一个漏洞窗口，多个服务器可以不必要地执行同一个请求。这种额外的工作可以通过在发出对冲请求之前等待第95分位数的预期延迟来限制，但这种方法只对一小部分请求有好处。允许更积极地使用具有适度资源消耗的对冲请求需要更快地取消请求。

一个常见的可变性来源是在请求开始执行前服务器上的排队延迟。对于许多服务来说，一旦一个请求被实际安排并开始执行，其完成时间的变异性就会大大降低。Mitzenmacher10说，允许客户端在enqueue时间根据队列长度在两个服务器之间进行选择，比起统一的随机方案，负载平衡性能有了指数级的提高。我们提倡的不是选择，而是将请求的副本同时排在多个服务器上，并允许服务器之间相互交流这些副本的最新状态。我们把服务器进行跨服务器状态更新的请求称为 "捆绑请求"。绑定请求的最简单形式是客户端将请求发送到两个不同的服务器，每个服务器都被标记为另一个服务器的身份（"绑定"）。当一个请求开始执行时，它向其对应的服务器发送一个取消消息。相应的请求，如果仍然在另一个服务器中排队，可以立即中止或大幅降低优先级。

有一个平均网络消息延迟的短暂窗口，两个服务器都可能开始执行请求，而取消消息都在飞往另一个服务器。发生这种情况的一个常见情况是，如果两个服务器的队列都是完全空的。因此，对于客户端来说，在发送第一个请求和发送第二个请求之间引入一个两倍于平均网络消息延迟的小延迟（在现代数据中心网络中为1ms或更少）是有用的。

谷歌在其集群级分布式文件系统的背景下实施这一技术，有效地减少了中位数和尾部延迟。表2列出了为BigTable的小型读取请求提供服务的时间，其中数据没有缓存在内存中，而是必须从底层文件系统中读取；每个文件块在不同机器上有三个副本。该表包括在两种情况下观察到的有和无捆绑请求的读取延迟。第一种情况是基准运行在孤立的集群中，在这种情况下，延迟变化主要来自自我干扰和常规集群管理活动。在这种情况下，在1毫秒后向另一个文件系统副本发送一个做跨服务器取消的捆绑请求，可以将中位延迟降低16%，并且沿着延迟分布的尾部越来越有效，在99.9分位延迟时实现近40%的降低。第二种情况与第一种情况类似，只是在同一个集群上还有一个大型的、并发的排序工作在运行，争夺共享文件系统中的相同磁盘资源。尽管由于较高的利用率，总体延迟较高，但通过前面讨论的捆绑请求技术，也实现了延迟曲线的类似减少。在运行一个并发的大型分类工作时，有捆绑请求的延迟情况与没有捆绑请求的大部分闲置集群的延迟情况几乎相同。附带请求允许将工作负载合并到一个集群中，从而使计算成本大幅降低。在表2的两种情况下，捆绑请求在磁盘利用率方面的开销都小于1%，这表明取消策略在消除冗余读取方面是有效的。

捆绑式请求和对冲式请求方案的一个替代方案是先探测远程队列，然后将请求提交给负载最少的服务器。10这可能是有益的，但不如同时向两个队列提交工作有效，主要原因有三个：负载水平在探测和请求时间之间可能会发生变化；由于基础系统和硬件的变化，请求服务时间可能难以估计；客户可能通过所有客户在同一时间挑选同一（负载最少的）服务器来创造临时热点。分布式最短定位时间优先系统9使用了另一种变体，即请求被发送到一台服务器，只有当初始服务器的缓存中没有该请求时才转发到副本，并使用跨服务器取消。

值得注意的是，这种技术并不局限于简单的复制，也适用于更复杂的编码方案（如Reed-Solomon），其中一个主要的请求被发送到具有所需数据块的机器，如果在短暂的延迟后没有收到响应，则向剩余的复制组的一个子集发出请求，足以重建所需的数据，整个集合形成一组绑定的请求。

还要注意的是，这里描述的这一类技术只有在导致变异性的现象不倾向于同时影响多个请求复制时才有效。我们希望这种不相关的现象在大规模系统中相当普遍。

## Cross-Request Long-Term Adaptations

在这里，我们转向适用于减少由更粗粒度的现象（如服务时间变化和负载不平衡）引起的延迟变化的技术。尽管许多系统试图以这样的方式对数据进行分区，使分区具有同等的成本，但由于两个原因，将单一分区静态分配给每台机器在实践中很少是足够的。首先，由于前面提到的原因（如热节流和共享工作负载干扰），底层机器的性能既不统一，也不随时间变化而变化。其次，将项目分配到分区中的异常值会导致数据引起的负载不平衡（例如，当某个项目变得流行，其分区的负载增加）。

**微观分区**。为了解决不平衡问题，谷歌的许多系统产生了比服务中的机器多得多的分区，然后对这些分区进行动态分配，并对特定的机器进行负载平衡。负载平衡是将这些小分区的责任从一台机器转移到另一台机器上的问题。例如，每台机器平均有20个分区，系统可以以大约5%的增量来减轻负载，所需时间是系统简单地将分区与机器进行一对一映射的1/20。BigTable分布式存储系统将数据存储在平板电脑中，每台机器同时管理20至1000个平板电脑。通过微分区，故障恢复的速度也得到了提高，因为当机器发生故障时，许多机器会接上一个工作单元。这种使用微分区的方法类似于Stoica12中描述的虚拟服务器概念和DeWitt等人的虚拟处理器分区技术6。

**选择性的复制**。微分区方案的一个改进是检测甚至预测某些可能导致负载不平衡的项目，并为这些项目创建额外的副本。然后，负载平衡系统可以使用额外的副本，将这些热门微分区的负载分散到多台机器上，而不必实际移动微分区。谷歌的主要网络搜索系统采用了这种方法，在多个微分区中为热门和重要的文件制作额外的副本。在谷歌网络搜索系统发展的不同时期，它还创建了偏向于特定文档语言的微分区，并随着查询语言的混合在一天中的变化而调整这些微分区的复制。查询组合也可能突然发生变化，例如，当亚洲数据中心的故障导致很大一部分亚洲语言的查询被引导到北美设施，实质性地改变其工作负载行为。

**延迟引起的概率**。通过观察系统中各种机器响应的延迟分布，中间服务器有时会检测到系统表现较好的情况，即排除一个特别慢的机器，或将其置于试用期。缓慢的来源经常是暂时性的现象，如不相关的网络流量的干扰或机器上另一个工作的CPU活动的高峰，缓慢往往在系统处于更大的负载下时才被注意。然而，系统会继续向这些被排除在外的服务器发出影子请求，收集它们的延迟统计数据，以便在问题缓解时将它们重新纳入服务中。这种情况有点特殊，因为在高负载期间，从实时系统中移除服务能力实际上会改善延时。

## Large Information Retrieval Systems

在大型信息检索（IR）系统中，速度不仅仅是一个性能指标；它是一个关键的质量指标，因为快速返回好的结果要比缓慢返回最好的结果好。有两种技术适用于此类系统，以及其他固有的处理不精确结果的系统。

足够好。在大型的IR系统中，一旦所有的叶子服务器中有足够的部分做出了回应，用户就可以通过得到稍微不完整的（"足够好的"）结果来换取更好的端到端延迟。一个特定的叶子服务器拥有最佳查询结果的几率不到1/1000，通过将语料库中最重要的文件复制到多个叶子服务器，几率进一步降低。由于等待速度极慢的服务器可能会使服务延迟达到不可接受的程度，因此谷歌的IR系统被调整为在整个语料库中可接受的部分被搜索到时，偶尔会回应出足够好的结果，同时小心翼翼地确保足够好的结果仍然很少。一般来说，足够好的方案也被用来跳过非必要的子系统，以提高响应速度；例如，如果广告或拼写纠正系统没有及时响应，则很容易跳过网络搜索的结果。

> A simple way to curb latency variability is to issue the same request to multiple replicas and use the results from whichever replica responds first.

金丝雀请求。在具有非常高的扇出度的系统中可能发生的另一个问题是，一个特定的请求行使一个未经测试的代码路径，导致成千上万的服务器同时崩溃或极长的延迟。为了防止这种相关的崩溃情况，谷歌的一些IR系统采用了一种叫做 "金丝雀请求 "的技术；根服务器并不是一开始就把一个请求发送给成千上万的叶子服务器，而是先把它发送给一个或两个叶子服务器。只有当根服务器在合理的时间内从金丝雀那里得到成功的响应时，才会对其余的服务器进行查询。如果服务器在金丝雀请求未完成时崩溃或挂起，系统会将该请求标记为潜在的危险，并通过不将其发送到其余叶子服务器来防止进一步执行。面对难以预测的编程错误以及恶意的拒绝服务攻击，金丝雀请求为后端提供了一种稳健性措施。

金丝雀请求阶段只增加了少量的整体延迟，因为系统必须只等待一个服务器的响应，产生的变化比等待所有服务器响应大型扇出请求要少得多；比较表1的第一行和最后一行。尽管金丝雀请求引起的延迟略有增加，但由于它们提供了额外的安全性，这种请求往往被用于谷歌所有大型扇出式搜索系统中的每一个请求。

## Mutations

到目前为止，我们所讨论的技术最适用于那些不对系统状态进行关键突变的操作，这涵盖了广泛的数据密集型服务。由于一些原因，容忍对状态进行突变的操作的延迟变化要容易一些。首先，这些服务中的延迟关键性修改的规模通常很小。第二，更新通常可以在响应用户之后，在关键路径之外进行。第三，许多服务的结构可以容忍不一致的更新模型，以实现（固有的更多的延迟容忍）突变。最后，对于那些需要一致更新的服务，最常用的技术是基于法定人数的算法（如Lamport的Paxos8）；因为这些算法必须只提交三到五个副本，所以它们本身是可以容忍尾部的。

## Hardware Trends and Their Effects

由于更积极的功率优化的出现和深亚微米级的制造挑战导致器件级的异质性，硬件级的变异性在未来可能会更高。器件的异质性与不断增加的系统规模相结合，将使通过软件技术容忍变异性随着时间的推移变得更加重要。幸运的是，一些新出现的硬件趋势将提高延迟容忍技术的有效性。例如，数据中心网络中更高的分割带宽和网络接口优化，减少了每个消息的开销（如远程直接内存访问），将减少绑定请求的成本，使得更有可能及时收到取消的消息，以避免重复工作。较低的每条消息的开销自然允许更细粒度的请求，有助于更好地复用和避免线头阻塞效应。

## Conclusion

提供下一代计算密集型、无缝互动的云服务需要持续响应的大规模计算系统，而这一点现在才开始被考虑到。随着系统规模的扩大，简单地消除所有性能变异的来源将无法实现这种响应性。容错技术之所以被开发出来，是因为在系统复杂度超过一定程度时，保证无故障运行变得不可行。同样地，正在为大规模服务开发容尾技术，因为消除所有的变异性来源也是不可行的。尽管解决特定延迟变异来源的方法是有用的，但最强大的尾部容忍技术可以减少延迟抖动，而不考虑根本原因。这些尾部容忍技术允许设计者继续为常见的情况进行优化，同时对不常见的情况提供弹性。我们已经概述了一小部分容尾技术，这些技术在谷歌的几个大规模软件系统中都很有效。随着互联网服务对越来越大、越来越复杂的仓库级系统的需求，以及底层硬件组件显示出更大的性能变化，它们的重要性只会增加。

虽然一些最强大的尾部容错技术需要额外的资源，但它们的开销可能相当小，通常依靠已经为容错提供的现有能力，同时产生大量的延迟改进。此外，这些技术中的许多可以封装在基线库和系统中，延迟的改善往往能从根本上简化应用层面的设计。除了实现大规模的低延迟，这些技术还可以在不牺牲服务响应性的情况下实现更高的系统利用率。

## Acknowledgments

We thank Ben Appleton, Zhifeng Chen, Greg Ganger, Sanjay Ghemawat, Ali Ghodsi, Rama Govindaraju, Lawrence Greenfield, Steve Gribble, Brian Gustafson, Nevin Heintze, Jeff Mogul, Andrew Moore, Rob Pike, Sean Quinlan, Gautham Thambidorai, Ion Stoica, Amin Vahdat, and T.N. Vijaykumar for their helpful feedback on earlier drafts and presentations of this work. Numerous people at Google have worked on systems that use these techniques.

References
1. Barroso, L.A. and Höelzle, U. The case for energy proportional computing. IEEE Computer 40, 12 (Dec. 2007), 3337.

2. Barroso, L.A. and Höelzle, U. The Datacenter as a Computer: An Introduction to the Design of Warehouse-scale Machines. Synthesis Series on Computer Architecture, Morgan & Claypool Publishers, May 2009.

3. Card, S.K., Robertson, G.G., and Mackinlay, J.D. The information visualizer: An information workspace. In Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems (New Orleans, Apr. 28May 2). ACM Press, New York, 1991, 181188.

4. Chang F., Dean J., Ghemawat, S., Hsieh, W.C., Wallach, D.A., Burrows, M., Chandra, T., Fikes, A., and Gruber, R.E. BigTable: A distributed storage system for structured data. In Proceedings of the Seventh Symposium on Operating Systems Design and Implementation (Seattle, Nov.). USENIX Association, Berkeley CA, 2006, 205218.

5. Charles, J., Jassi, P., Ananth, N.S., Sadat, A., and Fedorova, A. Evaluation of the Intel Core i7 Turbo Boost feature. In Proceedings of the IEEE International Symposium on Workload Characterization (Austin, TX, Oct. 46). IEEE Computer Society Press, 2009, 188197.

6. DeWitt, D.J., Naughton, J.F., Schneider, D.A., and Seshadri, S. Practical skew handling in parallel joins. In Proceedings of the 18th International Conference on Very Large Data Bases, Li-Yan Yuan, Ed. (Vancouver, BC, Aug. 2427). Morgan Kaufmann Publishers, Inc., San Francisco, 1992, 2740.

7. Google, Inc. Project Glass; http://g.co/projectglass

8. Lamport, L. The part-time parliament. ACM Transactions on Computer Systems 16, 2 (May 1998), 133169.

9. Lumb, C.R. and Golding, R. D-SPTF: Decentralized request distribution in brick-based storage systems. SIGOPS Operating System Review 38, 5 (Oct. 2004), 3747.

10. Mitzenmacher, M. The power of two choices in randomized load balancing. IEEE Transactions on Parallel and Distributed Computing 12, 10 (Oct. 2001), 10941104.

11. Mudge, T. and Hölzle, U. Challenges and opportunities for extremely energy-efficient processors. IEEE Micro 30, 4 (July 2010), 2024.

12. Stoica I., Morris, R., Karger, D., Kaashoek, F., and Balakrishnan, H. Chord: A scalable peer-to-peer lookup service for Internet applications. In Proceedings of SIGCOMM (San Diego, Aug. 2731). ACM Press, New York, 2001, 149160.

Back to Top

Authors
Jeffrey Dean (jeff@google.com) is a Google Fellow in the Systems Infrastructure Group of Google Inc., Mountain View, CA.

Luiz André Barroso (luiz@google.com) is a Google Fellow and technical lead of core computing infrastructure at Google Inc., Mountain View, CA.

Figures
UF1Figure. Probability of one-second service-level response time as the system scales and frequency of server-level high-latency outliers varies.

Tables
T1Table 1. Individual-leaf-request finishing times for a large fan-out service tree (measured from root node of the tree).

T2Table 2. Read latencies observed in a BigTable service benchmark.